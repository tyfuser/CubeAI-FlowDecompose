/**
 * CameraCapture Component
 * 
 * Captures frames from camera for realtime analysis.
 * Implements frame buffer capture (5-10 frames), JPEG compression,
 * Base64 encoding, and sliding window with overlap.
 * 
 * Requirements: 1.1, 1.2
 */
import React, { useEffect, useRef, useState, useCallback, forwardRef, useImperativeHandle } from 'react';

export interface CameraCaptureConfig {
  /** Number of frames per buffer (5-10 per Requirement 1.2) */
  bufferSize: number;
  /** Capture interval in milliseconds (500-1000ms per Requirement 1.1) */
  captureIntervalMs: number;
  /** JPEG compression quality (0-1) */
  jpegQuality: number;
  /** Target resolution width */
  targetWidth: number;
  /** Target resolution height */
  targetHeight: number;
  /** Overlap ratio for sliding window (0-1) */
  overlapRatio: number;
}

export interface FrameBuffer {
  frames: string[];  // Base64-encoded JPEG images
  fps: number;
  timestamp: number;
}

export interface CameraCaptureRef {
  startCapture: () => Promise<void>;
  stopCapture: () => void;
  isCapturing: boolean;
  getStream: () => MediaStream | null;
}

interface CameraCaptureProps {
  config?: Partial<CameraCaptureConfig>;
  onFrameBuffer?: (buffer: FrameBuffer) => void;
  onError?: (error: string) => void;
  onCameraReady?: () => void;
  onDebug?: (message: string) => void;
  className?: string;
  mirror?: boolean;
}

const DEFAULT_CONFIG: CameraCaptureConfig = {
  bufferSize: 8,           // 8 frames per buffer
  captureIntervalMs: 500,  // Capture every 500ms (2 buffers/second)
  jpegQuality: 0.75,       // 75% JPEG quality
  targetWidth: 320,        // Low-res for speed
  targetHeight: 240,
  overlapRatio: 0.3,       // 30% overlap with previous buffer
};

export const CameraCapture = forwardRef<CameraCaptureRef, CameraCaptureProps>(({
  config: userConfig,
  onFrameBuffer,
  onError,
  onCameraReady,
  onDebug,
  className = '',
  mirror = true,
}, ref) => {
  const config = { ...DEFAULT_CONFIG, ...userConfig };
  
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const frameBufferRef = useRef<string[]>([]);
  const captureIntervalRef = useRef<number | null>(null);
  const lastCaptureTimeRef = useRef<number>(0);
  const cameraReadyRef = useRef<boolean>(false);
  const isCapturingRef = useRef<boolean>(false);
  const captureFrameRef = useRef<(() => string | null) | null>(null);
  
  const [isCapturing, setIsCapturing] = useState(false);
  const [cameraReady, setCameraReady] = useState(false);
  const [cameraError, setCameraError] = useState<string | null>(null);
  const [captureCount, setCaptureCount] = useState(0);
  const [lastDebug, setLastDebug] = useState('');
  const [startCount, setStartCount] = useState(0);
  const [debugLogs, setDebugLogs] = useState<string[]>([]);
  
  // Add debug log with timestamp
  const addDebug = useCallback((module: string, message: string) => {
    const timestamp = new Date().toLocaleTimeString('zh-CN', { hour12: false });
    const log = `[${timestamp}][${module}] ${message}`;
    console.log(log);
    setDebugLogs(prev => [...prev.slice(-9), log]);
    setLastDebug(message);
  }, []);
  
  // Keep refs in sync with state
  useEffect(() => {
    cameraReadyRef.current = cameraReady;
    console.log('[CameraCapture] cameraReady state changed to:', cameraReady);
  }, [cameraReady]);
  
  useEffect(() => {
    isCapturingRef.current = isCapturing;
    console.log('[CameraCapture] isCapturing state changed to:', isCapturing);
  }, [isCapturing]);

  // Initialize camera - called on demand, not on mount
  const initCamera = useCallback(async () => {
    console.group('ğŸ” [CameraCapture] initCamera å¼€å§‹');
    console.log('[INIT] æ£€æŸ¥çŠ¶æ€:', {
      cameraReady: cameraReadyRef.current,
      hasStream: !!streamRef.current,
      videoRef: !!videoRef.current
    });
    
    if (cameraReadyRef.current || streamRef.current) {
      addDebug('INIT', 'æ‘„åƒå¤´å·²åˆå§‹åŒ–ï¼Œè·³è¿‡');
      console.log('[INIT] âœ“ æ‘„åƒå¤´å·²å°±ç»ªï¼Œè·³è¿‡åˆå§‹åŒ–');
      console.groupEnd();
      return true;
    }
    
    addDebug('INIT', 'å¼€å§‹åˆå§‹åŒ–æ‘„åƒå¤´...');
    console.log('[INIT] å¼€å§‹åˆå§‹åŒ–æ‘„åƒå¤´...');
    
    // è¯¦ç»†çš„æµè§ˆå™¨ç¯å¢ƒæ£€æŸ¥
    const browserInfo = {
      userAgent: navigator.userAgent,
      platform: navigator.platform,
      hasMediaDevices: !!navigator.mediaDevices,
      hasGetUserMedia: !!(navigator.mediaDevices?.getUserMedia),
      protocol: window.location.protocol,
      hostname: window.location.hostname,
      href: window.location.href,
      isSecureContext: window.isSecureContext,
      isLocalhost: window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1',
    };
    
    console.log('[INIT] æµè§ˆå™¨ç¯å¢ƒä¿¡æ¯:', browserInfo);
    addDebug('INIT', `æµè§ˆå™¨: ${browserInfo.userAgent.substring(0, 50)}...`);
    addDebug('INIT', `åè®®: ${browserInfo.protocol}, ä¸»æœº: ${browserInfo.hostname}`);
    
    // Check browser support
    if (!navigator.mediaDevices) {
      const errorMsg = 'æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´è®¿é—® API (navigator.mediaDevices ä¸å­˜åœ¨)';
      console.error('[INIT] âŒ', errorMsg);
      console.error('[INIT] æµè§ˆå™¨ä¿¡æ¯:', browserInfo);
      addDebug('INIT', `é”™è¯¯: ${errorMsg}`);
      setCameraError(errorMsg);
      onError?.(errorMsg);
      console.groupEnd();
      return false;
    }
    
    if (!navigator.mediaDevices.getUserMedia) {
      const errorMsg = 'æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´è®¿é—® API (getUserMedia ä¸å­˜åœ¨)';
      console.error('[INIT] âŒ', errorMsg);
      console.error('[INIT] navigator.mediaDevices:', navigator.mediaDevices);
      addDebug('INIT', `é”™è¯¯: ${errorMsg}`);
      setCameraError(errorMsg);
      onError?.(errorMsg);
      console.groupEnd();
      return false;
    }
    
    console.log('[INIT] âœ“ getUserMedia API å¯ç”¨');
    addDebug('INIT', 'getUserMedia API å¯ç”¨');

    // Check secure context
    const isSecureContext = window.isSecureContext || 
                            window.location.protocol === 'https:' || 
                            window.location.hostname === 'localhost' ||
                            window.location.hostname === '127.0.0.1';
    
    console.log('[INIT] å®‰å…¨ä¸Šä¸‹æ–‡æ£€æŸ¥:', {
      isSecureContext,
      windowIsSecureContext: window.isSecureContext,
      protocol: window.location.protocol,
      hostname: window.location.hostname,
      calculated: isSecureContext
    });
    addDebug('INIT', `å®‰å…¨ä¸Šä¸‹æ–‡: ${isSecureContext}, åè®®: ${window.location.protocol}`);
    
    if (!isSecureContext) {
      const errorMsg = `æ‘„åƒå¤´è®¿é—®éœ€è¦ HTTPS è¿æ¥ã€‚å½“å‰åè®®: ${window.location.protocol}, isSecureContext: ${window.isSecureContext}`;
      console.error('[INIT] âŒ éå®‰å…¨ä¸Šä¸‹æ–‡:', errorMsg);
      console.error('[INIT] è¯¦ç»†ä¿¡æ¯:', browserInfo);
      addDebug('INIT', `é”™è¯¯: ${errorMsg}`);
      setCameraError(errorMsg);
      onError?.(errorMsg);
      console.groupEnd();
      return false;
    }
    
    console.log('[INIT] âœ“ å®‰å…¨ä¸Šä¸‹æ–‡æ£€æŸ¥é€šè¿‡');

    try {
      console.log('[INIT] ğŸ“¹ å‡†å¤‡è¯·æ±‚æ‘„åƒå¤´æƒé™...');
      addDebug('INIT', 'è¯·æ±‚æ‘„åƒå¤´æƒé™...');
      
      const constraints = {
        video: {
          facingMode: 'environment',
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
        audio: false,
      };
      
      console.log('[INIT] è¯·æ±‚çº¦æŸ:', JSON.stringify(constraints, null, 2));
      console.log('[INIT] ç­‰å¾…ç”¨æˆ·æˆæƒ...');
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      
      console.log('[INIT] âœ… æ‘„åƒå¤´æƒé™å·²æˆäºˆï¼');
      console.log('[INIT] Stream ä¿¡æ¯:', {
        id: stream.id,
        active: stream.active,
        tracks: stream.getTracks().map(t => ({
          kind: t.kind,
          label: t.label,
          enabled: t.enabled,
          readyState: t.readyState,
          settings: t.getSettings()
        }))
      });
      
      // Log stream info
      const videoTrack = stream.getVideoTracks()[0];
      if (videoTrack) {
        const settings = videoTrack.getSettings();
        console.log('[INIT] è§†é¢‘è½¨é“è¯¦æƒ…:', {
          label: videoTrack.label,
          settings: settings,
          capabilities: videoTrack.getCapabilities()
        });
        addDebug('STREAM', `è§†é¢‘è½¨é“: ${videoTrack.label}`);
        addDebug('STREAM', `åˆ†è¾¨ç‡: ${settings.width}x${settings.height}`);
        addDebug('STREAM', `å¸§ç‡: ${settings.frameRate}`);
      } else {
        console.warn('[INIT] âš ï¸  æœªæ‰¾åˆ°è§†é¢‘è½¨é“');
      }
      
      streamRef.current = stream;
      console.log('[INIT] Stream å·²ä¿å­˜åˆ° streamRef');
      
      if (videoRef.current) {
        console.log('[INIT] è®¾ç½® video.srcObject...');
        addDebug('VIDEO', 'è®¾ç½® video.srcObject...');
        videoRef.current.srcObject = stream;
        console.log('[INIT] video.srcObject å·²è®¾ç½®');
        
        // Try to play immediately (user gesture context)
        console.log('[INIT] å°è¯•æ’­æ”¾è§†é¢‘...');
        addDebug('VIDEO', 'å°è¯•æ’­æ”¾è§†é¢‘...');
        try {
          await videoRef.current.play();
          console.log('[INIT] âœ… è§†é¢‘æ’­æ”¾æˆåŠŸ!');
          console.log('[INIT] è§†é¢‘å°ºå¯¸:', {
            videoWidth: videoRef.current.videoWidth,
            videoHeight: videoRef.current.videoHeight,
            readyState: videoRef.current.readyState,
            paused: videoRef.current.paused,
            muted: videoRef.current.muted
          });
          addDebug('VIDEO', 'è§†é¢‘æ’­æ”¾æˆåŠŸ!');
          addDebug('VIDEO', `videoWidth: ${videoRef.current.videoWidth}, videoHeight: ${videoRef.current.videoHeight}`);
          
          cameraReadyRef.current = true;
          setCameraReady(true);
          setCameraError(null);
          console.log('[INIT] âœ… æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆï¼');
          console.groupEnd();
          onCameraReady?.();
          return true;
        } catch (playError: any) {
          console.warn('[INIT] âš ï¸  ç«‹å³æ’­æ”¾å¤±è´¥:', playError);
          console.log('[INIT] é”™è¯¯è¯¦æƒ…:', {
            name: playError.name,
            message: playError.message,
            stack: playError.stack
          });
          addDebug('VIDEO', `æ’­æ”¾å¤±è´¥: ${playError.message}`);
          
          // Wait for loadedmetadata event
          console.log('[INIT] ç­‰å¾… loadedmetadata äº‹ä»¶...');
          addDebug('VIDEO', 'ç­‰å¾… loadedmetadata äº‹ä»¶...');
          return new Promise<boolean>((resolve) => {
            const video = videoRef.current!;
            
            const onLoaded = () => {
              console.log('[INIT] âœ… loadedmetadata äº‹ä»¶è§¦å‘');
              addDebug('VIDEO', 'loadedmetadata è§¦å‘');
              video.play().then(() => {
                console.log('[INIT] âœ… å»¶è¿Ÿæ’­æ”¾æˆåŠŸ');
                addDebug('VIDEO', 'å»¶è¿Ÿæ’­æ”¾æˆåŠŸ');
                cameraReadyRef.current = true;
                setCameraReady(true);
                setCameraError(null);
                console.log('[INIT] âœ… æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆï¼ˆå»¶è¿Ÿæ’­æ”¾ï¼‰');
                console.groupEnd();
                onCameraReady?.();
                resolve(true);
              }).catch((e) => {
                console.error('[INIT] âŒ å»¶è¿Ÿæ’­æ”¾å¤±è´¥:', e);
                addDebug('VIDEO', `å»¶è¿Ÿæ’­æ”¾å¤±è´¥: ${e.message}`);
                console.groupEnd();
                resolve(false);
              });
            };
            
            video.addEventListener('loadedmetadata', onLoaded, { once: true });
            console.log('[INIT] å·²æ³¨å†Œ loadedmetadata ç›‘å¬å™¨');
            
            // Timeout after 5 seconds
            setTimeout(() => {
              video.removeEventListener('loadedmetadata', onLoaded);
              console.warn('[INIT] âš ï¸  loadedmetadata è¶…æ—¶');
              addDebug('VIDEO', 'loadedmetadata è¶…æ—¶');
              console.groupEnd();
              resolve(false);
            }, 5000);
          });
        }
      } else {
        addDebug('VIDEO', 'é”™è¯¯: videoRef.current ä¸ºç©º');
        return false;
      }
    } catch (err: any) {
      console.error('[INIT] âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥:', err);
      console.error('[INIT] é”™è¯¯è¯¦æƒ…:', {
        name: err.name,
        message: err.message,
        constraint: err.constraint,
        stack: err.stack
      });
      addDebug('INIT', `æ‘„åƒå¤´é”™è¯¯: ${err.name} - ${err.message}`);
      let errorMsg = 'æ— æ³•è®¿é—®æ‘„åƒå¤´';
      
      if (err.name === 'NotAllowedError') {
        errorMsg = 'æ‘„åƒå¤´æƒé™è¢«æ‹’ç»ï¼Œè¯·å…è®¸æµè§ˆå™¨è®¿é—®æ‘„åƒå¤´';
        console.error('[INIT] âŒ ç”¨æˆ·æ‹’ç»äº†æ‘„åƒå¤´æƒé™');
      } else if (err.name === 'NotFoundError') {
        errorMsg = 'æœªæ‰¾åˆ°æ‘„åƒå¤´è®¾å¤‡';
        console.error('[INIT] âŒ æœªæ‰¾åˆ°æ‘„åƒå¤´è®¾å¤‡');
      } else if (err.name === 'NotReadableError') {
        errorMsg = 'æ‘„åƒå¤´è¢«å…¶ä»–åº”ç”¨å ç”¨';
        console.error('[INIT] âŒ æ‘„åƒå¤´è¢«å ç”¨');
      } else if (err.name === 'OverconstrainedError') {
        console.warn('[INIT] âš ï¸  çº¦æŸè¿‡ä¸¥ï¼Œå°è¯•ç®€åŒ–çº¦æŸ...');
        addDebug('INIT', 'å°è¯•ç®€åŒ–çº¦æŸ...');
        try {
          console.log('[INIT] ä½¿ç”¨ç®€åŒ–çº¦æŸé‡æ–°è¯·æ±‚...');
          const simpleStream = await navigator.mediaDevices.getUserMedia({
            video: true,
            audio: false,
          });
          console.log('[INIT] âœ… ç®€åŒ–çº¦æŸæˆåŠŸ');
          streamRef.current = simpleStream;
          if (videoRef.current) {
            videoRef.current.srcObject = simpleStream;
            await videoRef.current.play();
            cameraReadyRef.current = true;
            setCameraReady(true);
            setCameraError(null);
            console.log('[INIT] âœ… æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆï¼ˆç®€åŒ–çº¦æŸï¼‰');
            console.groupEnd();
            onCameraReady?.();
            return true;
          }
        } catch (retryErr: any) {
          console.error('[INIT] âŒ ç®€åŒ–çº¦æŸä¹Ÿå¤±è´¥:', retryErr);
          errorMsg = 'æ‘„åƒå¤´ä¸æ”¯æŒè¯·æ±‚çš„é…ç½®';
        }
      }
      
      console.error('[INIT] âŒ æœ€ç»ˆé”™è¯¯:', errorMsg);
      setCameraError(errorMsg);
      onError?.(errorMsg);
      console.groupEnd();
      return false;
    }
  }, [onError, onCameraReady, addDebug]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (captureIntervalRef.current) {
        clearInterval(captureIntervalRef.current);
      }
    };
  }, []);

  // Capture a single frame as Base64 JPEG - stored in ref for interval access
  const captureFrame = useCallback((): string | null => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    
    setLastDebug(`captureFrame called`);
    
    if (!video) {
      setLastDebug('é”™è¯¯: video ref ä¸ºç©º');
      return null;
    }
    
    if (!canvas) {
      setLastDebug('é”™è¯¯: canvas ref ä¸ºç©º');
      return null;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) {
      setLastDebug('é”™è¯¯: æ— æ³•è·å– canvas context');
      return null;
    }

    // Set canvas size to target resolution
    canvas.width = config.targetWidth;
    canvas.height = config.targetHeight;

    try {
      // Draw video frame to canvas (scaled down)
      ctx.drawImage(video, 0, 0, config.targetWidth, config.targetHeight);

      // Convert to JPEG Base64
      const dataUrl = canvas.toDataURL('image/jpeg', config.jpegQuality);
      
      setLastDebug(`å¸§æ•è·æˆåŠŸ ${dataUrl.length} bytes`);
      
      // Remove data URL prefix to get pure Base64
      return dataUrl.replace(/^data:image\/jpeg;base64,/, '');
    } catch (err) {
      setLastDebug(`é”™è¯¯: drawImage å¤±è´¥ ${err}`);
      return null;
    }
  }, [config.targetWidth, config.targetHeight, config.jpegQuality]);
  
  // Keep ref updated
  useEffect(() => {
    captureFrameRef.current = captureFrame;
  }, [captureFrame]);

  // Start capturing frames - use refs to avoid stale closure
  const startCapture = useCallback(async () => {
    setStartCount(prev => prev + 1);
    addDebug('CAPTURE', `startCapture è°ƒç”¨ #${startCount + 1}`);
    
    if (isCapturingRef.current) {
      addDebug('CAPTURE', 'å·²åœ¨å½•åˆ¶ä¸­ï¼Œè·³è¿‡');
      return;
    }
    
    // Initialize camera if not ready (user gesture context)
    if (!cameraReadyRef.current) {
      addDebug('CAPTURE', 'æ‘„åƒå¤´æœªå°±ç»ªï¼Œå¼€å§‹åˆå§‹åŒ–...');
      const success = await initCamera();
      if (!success) {
        addDebug('CAPTURE', 'æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥');
        return;
      }
    }
    
    addDebug('CAPTURE', `çŠ¶æ€: capturing=${isCapturingRef.current}, ready=${cameraReadyRef.current}`);
    
    // Check video element state
    const video = videoRef.current;
    if (video) {
      addDebug('CAPTURE', `video.readyState: ${video.readyState}`);
      addDebug('CAPTURE', `video.paused: ${video.paused}`);
      addDebug('CAPTURE', `video.videoWidth: ${video.videoWidth}`);
      addDebug('CAPTURE', `video.videoHeight: ${video.videoHeight}`);
    }

    const frameIntervalMs = config.captureIntervalMs / config.bufferSize;
    addDebug('CAPTURE', `å¸§é—´éš”: ${frameIntervalMs}ms, ç¼“å†²åŒºå¤§å°: ${config.bufferSize}`);
    
    isCapturingRef.current = true;
    setIsCapturing(true);
    frameBufferRef.current = [];
    lastCaptureTimeRef.current = Date.now();

    let intervalCallCount = 0;
    
    // Start interval with inline capture logic
    captureIntervalRef.current = window.setInterval(() => {
      intervalCallCount++;
      
      const video = videoRef.current;
      const canvas = canvasRef.current;
      
      if (!video) {
        addDebug('INTERVAL', `#${intervalCallCount} video ä¸ºç©º`);
        return;
      }
      
      if (!canvas) {
        addDebug('INTERVAL', `#${intervalCallCount} canvas ä¸ºç©º`);
        return;
      }
      
      // Log video state periodically
      if (intervalCallCount <= 3 || intervalCallCount % 10 === 0) {
        addDebug('INTERVAL', `#${intervalCallCount} video.readyState=${video.readyState}, paused=${video.paused}`);
      }

      const ctx = canvas.getContext('2d');
      if (!ctx) {
        addDebug('INTERVAL', `#${intervalCallCount} æ— æ³•è·å– context`);
        return;
      }

      canvas.width = config.targetWidth;
      canvas.height = config.targetHeight;

      try {
        ctx.drawImage(video, 0, 0, config.targetWidth, config.targetHeight);
        const dataUrl = canvas.toDataURL('image/jpeg', config.jpegQuality);
        const frame = dataUrl.replace(/^data:image\/jpeg;base64,/, '');
        
        const frameSize = Math.round(frame.length / 1024);
        
        frameBufferRef.current.push(frame);
        setCaptureCount(prev => prev + 1);
        
        if (intervalCallCount <= 3) {
          addDebug('FRAME', `#${intervalCallCount} æ•è·æˆåŠŸ, å¤§å°: ${frameSize}KB`);
        }
        
        // When buffer is full, emit and slide
        if (frameBufferRef.current.length >= config.bufferSize) {
          const now = Date.now();
          const timeDelta = now - lastCaptureTimeRef.current;
          const fps = lastCaptureTimeRef.current > 0 
            ? (config.bufferSize * 1000) / timeDelta 
            : 30;
          
          const buffer: FrameBuffer = {
            frames: [...frameBufferRef.current],
            fps: Math.round(fps * 10) / 10,
            timestamp: now,
          };
          
          const totalSize = Math.round(buffer.frames.reduce((sum, f) => sum + f.length, 0) / 1024);
          addDebug('SEND', `å‘é€ ${buffer.frames.length} å¸§, æ€»å¤§å°: ${totalSize}KB, FPS: ${buffer.fps}`);
          
          onFrameBuffer?.(buffer);
          
          // Slide window
          const overlapFrames = Math.floor(config.bufferSize * config.overlapRatio);
          frameBufferRef.current = frameBufferRef.current.slice(-overlapFrames);
          lastCaptureTimeRef.current = now;
        }
      } catch (err) {
        addDebug('INTERVAL', `#${intervalCallCount} é”™è¯¯: ${err}`);
      }
    }, frameIntervalMs);
    
    addDebug('CAPTURE', `å®šæ—¶å™¨å·²å¯åŠ¨: ID=${captureIntervalRef.current}`);
  }, [config, onFrameBuffer, addDebug, startCount, initCamera]);

  // Stop capturing frames
  const stopCapture = useCallback(() => {
    setLastDebug('åœæ­¢å½•åˆ¶');
    
    if (captureIntervalRef.current) {
      clearInterval(captureIntervalRef.current);
      captureIntervalRef.current = null;
    }
    isCapturingRef.current = false;
    setIsCapturing(false);
    frameBufferRef.current = [];
  }, []);

  // Expose methods via ref
  useImperativeHandle(ref, () => ({
    startCapture,
    stopCapture,
    isCapturing,
    getStream: () => streamRef.current,
  }), [startCapture, stopCapture, isCapturing]);

  return (
    <div className={`relative ${className}`}>
      {/* Video element */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        className={`w-full h-full object-cover ${mirror ? 'scale-x-[-1]' : ''}`}
      />
      
      {/* Hidden canvas for frame capture */}
      <canvas
        ref={canvasRef}
        className="hidden"
      />
      
      {/* Camera error overlay */}
      {cameraError && (
        <div className="absolute inset-0 bg-black/90 flex items-center justify-center p-4">
          <div className="bg-gray-800 rounded-lg p-4 max-w-sm border border-red-500/50">
            <h3 className="text-red-400 font-bold text-sm mb-2">âš ï¸ æ‘„åƒå¤´è®¿é—®å¤±è´¥</h3>
            <p className="text-white text-xs whitespace-pre-line">{cameraError}</p>
            <button
              onClick={() => window.location.reload()}
              className="mt-3 w-full bg-blue-600 hover:bg-blue-700 text-white px-3 py-1.5 rounded text-sm"
            >
              åˆ·æ–°é¡µé¢
            </button>
          </div>
        </div>
      )}
      
      {/* Capture indicator */}
      {isCapturing && (
        <div className="absolute top-2 right-2 flex items-center gap-1.5 bg-black/50 px-2 py-1 rounded-full">
          <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse" />
          <span className="text-white text-xs">REC</span>
        </div>
      )}
      
      {/* Internal debug display */}
      <div className="absolute bottom-2 left-2 right-2 bg-black/80 px-2 py-1 rounded text-xs text-white font-mono max-h-[150px] overflow-y-auto">
        <div className="flex justify-between mb-1">
          <span>ready: {cameraReady ? 'âœ“' : 'âœ—'} | cap: {isCapturing ? 'âœ“' : 'âœ—'}</span>
          <span>frames: {captureCount} | starts: {startCount}</span>
        </div>
        <div className="text-yellow-300 font-bold mb-1">
          {isCapturing ? `ğŸ”´ å®šæ—¶å™¨å·²å¯åŠ¨ #${startCount}` : 'â¸ï¸ æœªå¯åŠ¨'}
        </div>
        <div className="space-y-0.5 text-[10px]">
          {debugLogs.map((log, i) => (
            <div key={i} className="text-gray-300 truncate">{log}</div>
          ))}
        </div>
      </div>
    </div>
  );
});

CameraCapture.displayName = 'CameraCapture';

export default CameraCapture;
